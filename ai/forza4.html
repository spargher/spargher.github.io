<!DOCTYPE html>
<html lang="it">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Forza 4 - RL con TensorFlow.js, Self-Play e CNN</title>
  <style>
    body {
      font-family: sans-serif;
      max-width: 800px;
      margin: 2rem auto;
      text-align: center;
    }
    #board {
      display: grid;
      grid-template-columns: repeat(7, 60px);
      grid-gap: 5px;
      margin: 20px auto;
      width: max-content;
    }
    .cell {
      width: 60px;
      height: 60px;
      background: #ddd;
      border-radius: 50%;
      display: flex;
      justify-content: center;
      align-items: center;
      font-size: 24px;
      cursor: pointer;
    }
    .player {
      background: red;
    }
    .agent {
      background: yellow;
    }
    #message {
      font-size: 1.2rem;
      margin: 10px;
    }
    #stats {
      margin-top: 20px;
      font-size: 0.9rem;
    }
    .button-group button {
      margin: 5px;
      padding: 5px 10px;
      font-size: 1rem;
      cursor: pointer;
    }
  </style>
</head>
<body>
  <h1>Forza 4 - RL con TensorFlow.js e CNN</h1>
  <div id="message">Clicca su una colonna per giocare!</div>
  <div id="board"></div>
  <div class="button-group">
    <button id="resetBtn">Nuova Partita</button>
    <button id="saveModelBtn">Salva Modello</button>
    <button id="loadModelBtn">Carica Modello</button>
    <!-- Pulsanti Self-Play -->
    <button id="startSelfPlayBtn">Avvia Self-Play</button>
    <button id="stopSelfPlayBtn">Ferma Self-Play</button>
  </div>
  <div id="stats"></div>
  
  <!-- Includi TensorFlow.js -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest"></script>
  <script>
    /***********************
     * Parametri di RL
     ***********************/
    const learningRate = 0.001;
    const gamma = 0.95; // fattore di sconto
    let epsilon = 1.0;  // esplorazione iniziale
    const epsilonMin = 0.1;
    const epsilonDecay = 0.995;
    const agentMark = -1;  // per il computer
    const playerMark = 1;  // per il giocatore
    
    /***********************
     * Stato del Gioco
     ***********************/
    const ROWS = 6;
    const COLS = 7;
    let board = [];
    let gameOver = false;
    let experiences = []; // Esperienze per il training
    
    // Inizializza il tabellone (array di 42 elementi)
    function initBoard() {
      board = Array(ROWS * COLS).fill(0);
      gameOver = false;
      experiences = [];
      renderBoard();
      document.getElementById('message').textContent = "La partita è iniziata. Tocca una colonna per giocare!";
    }
    
    /***********************
     * Rendering del Tabellone
     ***********************/
    function renderBoard() {
      const boardDiv = document.getElementById('board');
      boardDiv.innerHTML = "";
      for (let i = 0; i < board.length; i++) {
        const cellDiv = document.createElement('div');
        cellDiv.classList.add('cell');
        cellDiv.dataset.index = i;
        // In modalità interattiva, il click è interpretato come mossa del giocatore
        cellDiv.addEventListener('click', () => playerMove(Math.floor(i % COLS)));
        if (board[i] === playerMark) {
          cellDiv.classList.add('player');
        } else if (board[i] === agentMark) {
          cellDiv.classList.add('agent');
        }
        boardDiv.appendChild(cellDiv);
      }
    }
    
    /***********************
     * Logica di Forza 4
     ***********************/
    // Restituisce la riga disponibile nella colonna (oppure -1 se piena)
    function getAvailableRow(col) {
      for (let row = ROWS - 1; row >= 0; row--) {
        if (board[row * COLS + col] === 0) {
          return row;
        }
      }
      return -1;
    }
    
    // Inserisce una pedina nella colonna data per il segno indicato
    function dropPiece(col, mark) {
      const row = getAvailableRow(col);
      if (row !== -1) {
        board[row * COLS + col] = mark;
        return row;
      }
      return -1;
    }
    
    // Verifica se c'è un vincitore per un determinato segno (controllo orizzontale, verticale, diagonale)
    function checkWinner(mark) {
      // Orizzontale
      for (let row = 0; row < ROWS; row++) {
        for (let col = 0; col < COLS - 3; col++) {
          if (board[row * COLS + col] === mark &&
              board[row * COLS + col + 1] === mark &&
              board[row * COLS + col + 2] === mark &&
              board[row * COLS + col + 3] === mark) {
            return true;
          }
        }
      }
      // Verticale
      for (let col = 0; col < COLS; col++) {
        for (let row = 0; row < ROWS - 3; row++) {
          if (board[row * COLS + col] === mark &&
              board[(row+1) * COLS + col] === mark &&
              board[(row+2) * COLS + col] === mark &&
              board[(row+3) * COLS + col] === mark) {
            return true;
          }
        }
      }
      // Diagonale ascendente
      for (let row = 3; row < ROWS; row++) {
        for (let col = 0; col < COLS - 3; col++) {
          if (board[row * COLS + col] === mark &&
              board[(row-1) * COLS + col + 1] === mark &&
              board[(row-2) * COLS + col + 2] === mark &&
              board[(row-3) * COLS + col + 3] === mark) {
            return true;
          }
        }
      }
      // Diagonale discendente
      for (let row = 0; row < ROWS - 3; row++) {
        for (let col = 0; col < COLS - 3; col++) {
          if (board[row * COLS + col] === mark &&
              board[(row+1) * COLS + col + 1] === mark &&
              board[(row+2) * COLS + col + 2] === mark &&
              board[(row+3) * COLS + col + 3] === mark) {
            return true;
          }
        }
      }
      return false;
    }
    
    // Verifica se il tabellone è pieno
    function isBoardFull() {
      return board.every(cell => cell !== 0);
    }
    
    /***********************
     * Q-Network e RL Agent (con CNN)
     ***********************/
    let model;
    // Crea il Q-network con un layer CNN
    async function createModel() {
      model = tf.sequential();
      // Inizialmente, il modello riceve un vettore di 42 elementi, che viene rimodellato in [6,7,1]
      model.add(tf.layers.reshape({targetShape: [ROWS, COLS, 1], inputShape: [ROWS * COLS]}));
      // Layer CNN per estrarre pattern spaziali
      model.add(tf.layers.conv2d({
        filters: 32,
        kernelSize: 3,
        activation: 'relu',
        padding: 'same'
      }));
      // Appiattiamo l'output della CNN
      model.add(tf.layers.flatten());
      // Uno o più layer densi per processare le features estratte
      model.add(tf.layers.dense({ units: 64, activation: 'relu' }));
      // Layer di output: 7 possibili azioni
      model.add(tf.layers.dense({ units: COLS, activation: 'linear' }));
      model.compile({optimizer: tf.train.adam(learningRate), loss: 'meanSquaredError'});
    }
    
    // Restituisce lo stato corrente come tensore [1, 42] (float32)
    function getStateTensor() {
      return tf.tensor2d([board], [1, ROWS * COLS], 'float32');
    }
    
    // L'agente sceglie la mossa tramite strategia epsilon-greedy (modalità interattiva)
    async function agentMove() {
      if (gameOver) return;
      const stateTensor = getStateTensor();
      let action;
      if (Math.random() < epsilon) {
        // Esplorazione: scegli mossa casuale valida
        const validActions = [];
        for (let col = 0; col < COLS; col++) {
          if (getAvailableRow(col) !== -1) validActions.push(col);
        }
        action = validActions[Math.floor(Math.random() * validActions.length)];
      } else {
        // Sfruttamento: usa la rete per scegliere la mossa con il Q massimo
        const qValues = model.predict(stateTensor);
        const qArray = await qValues.data();
        for (let col = 0; col < COLS; col++) {
          if (getAvailableRow(col) === -1) qArray[col] = -Infinity;
        }
        action = qArray.indexOf(Math.max(...qArray));
      }
      tf.dispose(stateTensor);
      
      // Esegue la mossa dell'agente
      const row = dropPiece(action, agentMark);
      if (row === -1) {
        console.log("Mossa non valida scelta dall'agente, riprovo.");
        return agentMove();
      }
      renderBoard();
      
      // Registra l'esperienza per la mossa dell'agente (modalità interattiva)
      const nextStateTensor = getStateTensor();
      experiences.push({
        state: board.slice(), // copia dello stato dopo la mossa
        action: action,
        reward: 0,
        nextState: board.slice(),
        done: false,
        demo: false
      });
      tf.dispose(nextStateTensor);
      
      // Verifica se l'agente ha vinto
      if (checkWinner(agentMark)) {
        gameOver = true;
        updateExperienceRewards(-1);
        document.getElementById('message').textContent = "Il computer ha vinto!";
        await trainFromExperiences();
        updateEpsilon();
        updateStats("Computer");
        return;
      }
      // Pareggio
      if (isBoardFull()) {
        gameOver = true;
        document.getElementById('message').textContent = "Pareggio!";
        await trainFromExperiences();
        updateEpsilon();
        updateStats("Pareggio");
        return;
      }
    }
    
    /***********************
     * Training e Aggiornamento
     ***********************/
    // Alla fine della partita, aggiorna il reward per tutte le esperienze raccolte (modalità interattiva)
    function updateExperienceRewards(finalReward) {
      experiences.forEach(exp => {
        exp.reward = finalReward;
        exp.done = true;
      });
    }
    
    // Effettua il training sul batch di esperienze raccolte
    async function trainFromExperiences() {
      if (experiences.length === 0) return;
      const states = [];
      const targets = [];
      experiences.forEach(exp => {
        states.push(exp.state);
        const stateTensor = tf.tensor2d([exp.state], [1, ROWS * COLS], 'float32');
        const qValuesTensor = model.predict(stateTensor);
        const qValues = qValuesTensor.dataSync();
        tf.dispose([stateTensor, qValuesTensor]);
        let target = Array.from(qValues);
        if (exp.done) {
          target[exp.action] = exp.reward;
        } else {
          const nextStateTensor = tf.tensor2d([exp.nextState], [1, ROWS * COLS], 'float32');
          const nextQ = model.predict(nextStateTensor);
          const nextQValues = nextQ.dataSync();
          tf.dispose([nextStateTensor, nextQ]);
          target[exp.action] = exp.reward + gamma * Math.max(...nextQValues);
        }
        targets.push(target);
      });
      
      const xs = tf.tensor2d(states, [states.length, ROWS * COLS], 'float32');
      const ys = tf.tensor2d(targets, [targets.length, COLS], 'float32');
      await model.fit(xs, ys, {epochs: 1, verbose: 0});
      xs.dispose();
      ys.dispose();
      experiences = [];
    }
    
    // Aggiorna epsilon per ridurre l'esplorazione
    function updateEpsilon() {
      if (epsilon > epsilonMin) {
        epsilon *= epsilonDecay;
      }
    }
    
    /***********************
     * Gestione del Gioco - Modalità Interattiva
     ***********************/
    // Mossa del giocatore (interattiva)
    async function playerMove(col) {
      if (gameOver) return;
      // Salva lo stato prima della mossa
      const prevState = board.slice();
      const row = dropPiece(col, playerMark);
      if (row === -1) return;  // colonna piena
      renderBoard();
      
      // Registra l'esperienza della mossa del giocatore (demonstration)
      experiences.push({
        state: prevState,
        action: col,
        reward: 0,
        nextState: board.slice(),
        done: false,
        demo: true
      });
      
      if (checkWinner(playerMark)) {
        gameOver = true;
        updateExperienceRewards(1);
        document.getElementById('message').textContent = "Hai vinto!";
        await trainFromExperiences();
        updateEpsilon();
        updateStats("Giocatore");
        return;
      }
      if (isBoardFull()) {
        gameOver = true;
        document.getElementById('message').textContent = "Pareggio!";
        await trainFromExperiences();
        updateEpsilon();
        updateStats("Pareggio");
        return;
      }
      
      // Ora tocca all'agente (modalità interattiva)
      await agentMove();
    }
    
    /****************************************************
     * Modalità Self-Play (Entrambe le mosse sono agenti)
     ****************************************************/
    
    // Funzione per eseguire una mossa in modalità self-play
    // Il parametro "mark" indica il segno del giocatore corrente (es. +1 o -1)
    async function agentSelfPlayMove(mark) {
      if (gameOver) return;
      const state = board.slice();
      const stateTensor = tf.tensor2d([state], [1, ROWS * COLS], 'float32');
      let action;
      if (Math.random() < epsilon) {
        // Esplorazione: scegli una mossa valida casuale
        const validActions = [];
        for (let col = 0; col < COLS; col++) {
          if (getAvailableRow(col) !== -1) validActions.push(col);
        }
        action = validActions[Math.floor(Math.random() * validActions.length)];
      } else {
        // Sfruttamento: usa la rete per scegliere la mossa migliore
        const qValues = model.predict(stateTensor);
        const qArray = await qValues.data();
        for (let col = 0; col < COLS; col++) {
          if (getAvailableRow(col) === -1) qArray[col] = -Infinity;
        }
        action = qArray.indexOf(Math.max(...qArray));
        tf.dispose(qValues);
      }
      tf.dispose(stateTensor);
      
      const row = dropPiece(action, mark);
      if (row === -1) {
        console.log("Mossa non valida in self-play, riprovo.");
        return agentSelfPlayMove(mark);
      }
      renderBoard();
      
      // Registra l'esperienza includendo il "mark" per sapere a chi appartiene la mossa
      experiences.push({
        state: state,
        action: action,
        reward: 0,
        nextState: board.slice(),
        done: false,
        demo: false,
        mark: mark
      });
      
      // Verifica se questa mossa ha vinto o se il tabellone è pieno
      if (checkWinner(mark)) {
        gameOver = true;
      }
      if (isBoardFull()) {
        gameOver = true;
      }
    }
    
    // Simula una partita in modalità self-play in cui entrambi i giocatori sono agenti
    async function simulateSelfPlayGame() {
      initBoard();
      // Alterniamo i turni: partiamo con mark = playerMark (ad es. +1) e poi agentMark (-1)
      let currentMark = playerMark;
      while (!gameOver) {
        await agentSelfPlayMove(currentMark);
        if (gameOver) break;
        // Alterna il turno
        currentMark = (currentMark === playerMark) ? agentMark : playerMark;
        // Breve pausa per rendere visibili le mosse (opzionale)
        await sleep(100);
      }
      
      // Determina il risultato e aggiorna i reward per ogni esperienza:
      let winner = null;
      if (checkWinner(playerMark)) winner = playerMark;
      else if (checkWinner(agentMark)) winner = agentMark;
      
      if (winner === null) {
        experiences.forEach(exp => {
          exp.reward = 0;
          exp.done = true;
        });
        document.getElementById('message').textContent = "Pareggio in Self-Play!";
        updateStats("SelfPlay Pareggio");
      } else {
        experiences.forEach(exp => {
          exp.reward = (exp.mark === winner) ? 1 : -1;
          exp.done = true;
        });
        document.getElementById('message').textContent = (winner === playerMark) ? "Self-Play: il giocatore (mark +1) ha vinto!" : "Self-Play: il giocatore (mark -1) ha vinto!";
        updateStats((winner === playerMark) ? "SelfPlay Player" : "SelfPlay Agent");
      }
      
      await trainFromExperiences();
      updateEpsilon();
    }
    
    // Funzione di pausa (await sleep(ms))
    function sleep(ms) {
      return new Promise(resolve => setTimeout(resolve, ms));
    }
    
    // Loop continuo per la modalità self-play
    let selfPlayRunning = false;
    async function selfPlayLoop() {
      while (selfPlayRunning) {
        await simulateSelfPlayGame();
        await sleep(100);
      }
      document.getElementById('message').textContent = "Self-Play fermato.";
    }
    
    function startSelfPlay() {
      if (!selfPlayRunning) {
        selfPlayRunning = true;
        document.getElementById('message').textContent = "Self-Play avviato...";
        selfPlayLoop();
      }
    }
    
    function stopSelfPlay() {
      selfPlayRunning = false;
    }
    
    /***********************
     * Aggiornamento delle Statistiche
     ***********************/
    let gamesPlayed = 0;
    const results = { "Giocatore": 0, "Computer": 0, "Pareggio": 0, "SelfPlay Player": 0, "SelfPlay Agent": 0, "SelfPlay Pareggio": 0 };
    function updateStats(result) {
      gamesPlayed++;
      if (!results[result]) results[result] = 0;
      results[result]++;
      document.getElementById('stats').textContent =
        `Partite giocate: ${gamesPlayed} | Vincite Giocatore: ${results["Giocatore"]} | Vincite Computer: ${results["Computer"]} | Pareggi: ${results["Pareggio"]} | Self-Play (Player): ${results["SelfPlay Player"]} | Self-Play (Agent): ${results["SelfPlay Agent"]} | Self-Play (Pareggio): ${results["SelfPlay Pareggio"]}`;
    }
    
    /***********************
     * Salvataggio / Caricamento del Modello
     ***********************/
    async function saveModel() {
      try {
        await model.save('localstorage://connect4-model');
        localStorage.setItem('connect4-epsilon', JSON.stringify(epsilon));
        alert("Modello salvato con successo!");
      } catch (err) {
        console.error("Errore nel salvataggio del modello: ", err);
      }
    }
    
    async function loadModel() {
      try {
        model = await tf.loadLayersModel('localstorage://connect4-model');
        model.compile({optimizer: tf.train.adam(learningRate), loss: 'meanSquaredError'});
        const savedEpsilon = localStorage.getItem('connect4-epsilon');
        if (savedEpsilon) {
          epsilon = JSON.parse(savedEpsilon);
        }
        alert("Modello caricato con successo!");
      } catch (err) {
        console.error("Errore nel caricamento del modello: ", err);
        alert("Nessun modello salvato trovato.");
      }
    }
    
    /***********************
     * Setup Iniziale e Event Listeners
     ***********************/
    document.getElementById('resetBtn').addEventListener('click', initBoard);
    document.getElementById('saveModelBtn').addEventListener('click', saveModel);
    document.getElementById('loadModelBtn').addEventListener('click', loadModel);
    document.getElementById('startSelfPlayBtn').addEventListener('click', startSelfPlay);
    document.getElementById('stopSelfPlayBtn').addEventListener('click', stopSelfPlay);
    
    (async function() {
      await createModel();
      initBoard();
    })();
    
  </script>
</body>
</html>
